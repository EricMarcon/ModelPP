---
title: "fichier2"
author: "Léna KLAY"
date: "5/17/2019"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

````{r library}
rm(list=objects())
graphics.off()

library(INLA)
library(spatstat)
library(inlabru)
library(stats)
library(graphics)
library(lme4)
library(sp)
library(ggplot2)
library(mgcv)
library(raster)

#setwd("~/Desktop/stage/code_r/")
setwd("C:/Users/lena.klay/Desktop/guyane_new/code_r/")
#init.tutorial()
```

# Données de Paracou
```{r}

load("C:/Users/lena.klay/Desktop/guyane_new/paracou/Parcelle16_2018.Rdata")


# Données de 2015 uniquement
p16 = Parcelle16[Parcelle16$CensusYear==2015,]

# Fonction donnant les coordonnées sur l'ensemble de la parcelle 16
coord = function(Xfield,Yfield,c){
  xy = matrix(rep(0,2*length(Xfield)), ncol = 2, nrow = length(Xfield))
  xy[,1] = 100*((c-1)%%5)+Xfield
  xy[,2] = 100*(4-floor((c-1)/5))+Yfield
  return(xy)}

# Verification
c_essai=c(1,5,21,25)
Xfield_essai=c(0,0,0,0)
Yfield_essai=c(0,0,0,0)
plot(coord(Xfield_essai, Yfield_essai,c_essai), xlim=c(0,500), ylim=c(0,500),xlab="x",ylab="y", col="red")
abline(v=seq(0,500,100), h=seq(0,500,100))

# Rajout de ces coordonnées dans le dataframe
p16$X = coord(p16$Xfield,p16$Yfield,p16$SubPlot)[,1]
p16$Y = coord(p16$Xfield,p16$Yfield,p16$SubPlot)[,2]




# Analyse descriptive rapide des données

plot(p16$X,p16$Y,pch=20)
min(p16$X);min(p16$Y);max(p16$X);max(p16$Y)  # 0, 0, 500, 509 

# Certaines valeurs sortent du cadre (en haut), on va donc les supprimer
if(sum(p16$Y>500)!=0){
p16 = p16[-which(p16$Y>500),]}

# Grande diversité au sein des espèces     
plot(p16$X,p16$Y,pch=20, col=as.factor(p16$Species))

# Quelques espèces
plot(p16$X[p16$Species=="albiflora"],p16$Y[p16$Species=="albiflora"],pch=20, main="albiflora")
plot(p16$X[p16$Species=="americana"],p16$Y[p16$Species=="americana"],pch=20, main="americana")
plot(p16$X[p16$Species=="alba"],p16$Y[p16$Species=="alba"],pch=20, main="alba")
```




# Préparation des données

coord_pts : mesh 1 (parcelle de 500x500)
coord_pts_small : mesh 2 et 3 (parcelle ramenée à une taille de 5x5) (voir explications mesh 2)

On fait d'abord l'étude sur une espèce (americana) pour voir si ça marche :

```{r}

# dataframe des coordonnées
coord_pts = data.frame(x = p16$X[p16$Species=="americana"], y = p16$Y[p16$Species=="americana"])
nb_obs = nrow(coord_pts)
coord_pts_small = coord_pts/100

# création de d'objet ppp point pattern à partir des coordonnées
ppp_coord_pts = ppp(coord_pts$x, coord_pts$y, c(0,500), c(0,500))
ppp_coord_pts_small = ppp(coord_pts_small$x, coord_pts_small$y, c(0,5), c(0,5))

# transformation en SpatialPointDataFrame
coordinates(coord_pts) = c("x", "y")    
coordinates(coord_pts_small) = c("x", "y")    

coord_pts
coord_pts_small

# découpage du domaine en une grille
nb_carres_par_cote = 10
grid = raster(xmn=0, ymn=0, xmx=500, ymx=500, res=500/nb_carres_par_cote)
grid[] = 0                                                  # grid[] : nombre d'observations dans chaque cellule

# on compte pour chaque cellule de la grille, le nombre d'observations qu'elle contient
tab = table(cellFromXY(grid, coord_pts))
grid[as.numeric(names(tab))] = tab
plot(grid); points(coord_pts, pch=20)


val = data.frame(coordinates(grid), count=grid[])
val_small = data.frame(coordinates(grid)/100, count=grid[])

coordinates(val) <- c("x", "y")
coordinates(val_small) <- c("x", "y")

```

# Construction des mesh

## Construction mesh 1 (x.loc)
```{r}
# Mesh
mesh1 = inla.mesh.2d(loc = cbind(p16$X[p16$Species=="americana"], p16$Y[p16$Species=="americana"]), max.edge = 20) 
ggplot() + gg(mesh1) + gg(coord_pts)
```

## Construction mesh 2 (boundary)

Pour une raison inconnue, le mesh a du mal à se construire (très long) pour des côtés de longueur supérieur ou égale à 50... on va donc diviser nos coordonnées par 100 et créer le mesh sur un carré de 5x5.

```{r}
# Boundary
bnd <- spoly(data.frame(lon =  c(0, 5, 5, 0, 0), lat = c(0, 0, 5, 5, 0)),  # à l'échelle un centième
             crs=inla.CRS("longlat"))  

# Mesh
mesh2 = inla.mesh.2d(boundary=bnd, max.edge = 0.2) 
ggplot() + gg(mesh2) + gg(coord_pts_small) 
```



### Construction mesh 3 (meshbuider)

Paramétrisation
- Mesh vertex seed points variable name(s) : coord_pts_small
- Inner boundary variable name(s) : boundary


```{r}
# Boundary
bnd <- spoly(data.frame(lon =  c(0, 5, 5, 0, 0), lat = c(0, 0, 5, 5, 0)),  # à l'échelle un centième
             crs=inla.CRS("longlat"))  

# meshbuilder()

## Build boundary information:
## (fmesher supports SpatialPolygons, but this app is not (yet) intelligent enough for that.)
boundary <- list(NULL, as.inla.mesh.segment(bnd))

## Build the mesh:
mesh.loc <- coord_pts_small
mesh3 <- inla.mesh.2d(loc=mesh.loc,
                     boundary=boundary,
                     max.edge=c(0.18, 0.74),
                     min.angle=c(30, 21),
                     max.n=c(48000, 16000), ## Safeguard against large meshes.
                     max.n.strict=c(128000, 128000), ## Don't build a huge mesh!
                     cutoff=0.008, ## Filter away adjacent points.
                     offset=c(0.16, 0.43)) ## Offset for extra boundaries, if needed.

# Plot the mesh:
ggplot() + gg(mesh3) + gg(coord_pts_small) + gg(bnd)
```


# Poisson homogène
```{r Poisson}

fit_poisson_h <- bru(count ~ Intercept, val_small, family="poisson")
summary(fit_poisson_h)

pix <- pixels(mesh3, nx = 200, ny = 200)                  # résolution du graph
lambda <- predict(fit_poisson_h, pix, ~ exp(Intercept))

ggplot() + gg(lambda) + gg(bnd) + ggtitle("Posterior mean") + coord_fixed()

plot(fit_poisson_h, "Intercept")
```

```{r verification}

nb_obs/nb_carres_par_cote**2        # densité théorique
exp(0.4699773)                      # moyenne du lambda du poisson homogène  

# commande qui me donne la moy de l'intercept ? à trouver....
```



# Poisson inhomogène
```{r Poisson}

# Mesh choisi
mesh = mesh3

# Champ sur le mesh (loi à priori)
model_matern = inla.spde2.pcmatern(mesh, prior.sigma = c(10, 0.01), prior.range = c(1, 0.01))

fit_poisson <- bru(count ~ field(map = coordinates, model = model_matern) + Intercept, val_small, family="poisson")
summary(fit_poisson)
```

```{r verif}
pix <- pixels(mesh, nx = 200, ny = 200)                                          # résolution du graph
lambda <- predict(fit_poisson, pix, ~ exp(field + Intercept))

plot(density(ppp_coord_pts_small)*(5/nb_carres_par_cote), main="densité obs.")   # densité observée
plot(lambda["mean"], main="moyenne loi posterior")                               # moyenne de la loi à posteriori


# on renormalise car la fonction density nous donne le nombre de points moyen par carré unité.
# peut-on afficher density avec ggplot ?

plot(fit_poisson, "Intercept")
plot(spde.posterior(fit_poisson, "field", what = "range"))
plot(spde.posterior(fit_poisson, "field", what = "log.variance"))
```

# Cox homogène

```{r Cox}

fit_cox_h <- lgcp(coordinates ~ Intercept, val_small, samplers = bnd)
summary(fit_cox_h)

pix <- pixels(mesh3, nx = 200, ny = 200)               # résolution du graph
lambda <- predict(fit_cox_h, pix, ~ exp(Intercept))

ggplot() + gg(lambda["mean"]) + coord_fixed()

plot(fit_cox_h, "Intercept")
```
Documentation fonction K de Ripley : https://www.rdocumentation.org/packages/spatstat/versions/1.59-0/topics/Kest
```{r verif}
k_ripley = Kest(ppp_coord_pts_small)
k_ripley
plot.fv(k_ripley)
```
$K_{pois}$ nous donne la fonction k ripley d'une distribution de poisson homogène (H0). Les trois autres courbes sont trois façons différentes d'approcher la fonction k ripley de nos données. Ces trois courbes se trouvent au-dessus de la courbe $K_{pois}$, nos données sont donc aggrégées.



# Cox inhomogène
```{r Cox}

# Mesh choisi
mesh = mesh3

# Champ sur le mesh (loi à priori)
model_matern = inla.spde2.pcmatern(mesh, prior.sigma = c(0.1, 0.01), prior.range = c(5, 0.01))

fit_cox <- lgcp(coordinates ~ field(map = coordinates, model = model_matern) + Intercept, val_small, samplers = bnd)
summary(fit_cox)
```


```{r verif}
# couleurs centrées sur la valeur ... pour l'affichage
colsc <- function(...) {
  scale_fill_gradientn(colours = rev(RColorBrewer::brewer.pal(11,"RdYlBu")),
                       limits = range(..., na.rm=TRUE))}


pix <- pixels(mesh, nx = 200, ny = 200)                       # résolution du graph
lambda <- predict(fit_cox, pix, ~ exp(field + Intercept))

ggplot() + gg(lambda) + gg(bnd) + coord_equal() + colsc(lambda["mean"]$mean)

plot(fit_cox, "Intercept")
plot(spde.posterior(fit_cox, "field", what = "range"))
plot(spde.posterior(fit_cox, "field", what = "log.variance"))

```

```{r verif}
k_ripley_inhom = Kinhom(ppp_coord_pts_small)
k_ripley_inhom
plot(k_ripley_inhom)
```
On observe un phénomène d'agrégation dans un rayon de 0.2 à 0.9, puis le phénomène se gomme (la répartition des points se rapproche d'une distribution homogène).

```{r verif}

noeuds_mesh = ipoints(bnd, mesh)       
# noeuds du maillage sous la forme d'un SpatialPointsDataFrame. Chaque point a un poids qui lui est associé et qui est tel que la somme pondérée (par ces poids) d'une fonction évaluée en ces points est l'intégrale de cette fonction sur le mesh approximée par les fonctions de base linéaires.

lambda_abundance = predict(fit_cox, noeuds_mesh, ~ sum(weight * exp(field + Intercept))) 
# on prédit sur les noeuds du mesh, la valeur de lambda par rapport aux valeurs du champ pondérées par nos estimations ?


tree = predict(fit_cox, noeuds_mesh,
               ~ data.frame(N = 0:500,dpois(0:500, lambda = sum(weight * exp(field + Intercept)))))
# on prédit ? sur les noeuds du mesh par rapport aux densités calculées par nos estimations et la loi de poisson

# marginal = list(x=c(), y=c()) with density values y at locations x, 
inla.qmarginal(c(0.025, 0.5, 0.975), marginal = list(x=tree$N, y = tree$mean))
inla.emarginal(identity, marginal = list(x=tree$N, y = tree$mean))


tree$plugin_estimate <- dpois(tree$N, lambda=lambda_abundance$mean)
ggplot(data = tree) + geom_line(aes(x = N, y = mean, colour = "Posterior")) +  geom_line(aes(x = N, y = plugin_estimate, colour = "Plugin"))
```
Ici nous sommes censés obtenir 160 qui est le nombre d'observations, mais le résultat est seulement de 100. 



Choses à améliorer :
- pourquoi ne peut-on pas définir une frontière de longueur 500 ?
- quelle est la commande pour obtenir directement les coefficients (moyens par ex) des modèles fit de la fonction bru ?
- peut-on faire un plot de la fonction density (de spatstat) avec ggplot2 ?
- choix des priors ?
- amélioration du mesh ?